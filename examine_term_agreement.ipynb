{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\alecr\\Projects\\assignments\\Korbit_B\\wikipedia_machine_learning.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data.apply(lambda x: x[2], axis=1)\n",
    "titles = data.apply(lambda x: x[0], axis=1)\n",
    "urls = data.apply(lambda x: x[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data.apply(lambda x: x[2], axis=1)\n",
    "titles = data.apply(lambda x: x[0], axis=1)\n",
    "urls = data.apply(lambda x: x[1], axis=1)\n",
    "df = pd.concat([titles,urls,articles],axis=1)\n",
    "df.columns = ['title', 'url','original_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>original_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Outline of computer vision</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Outline_of_compu...</td>\n",
       "      <td>The following outline is provided as an overvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Outline of natural language processing</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Outline_of_natur...</td>\n",
       "      <td>The following outline is provided as an overvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Outline of robotics</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Outline_of_robotics</td>\n",
       "      <td>The following outline is provided as an overvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Accuracy paradox</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Accuracy_paradox</td>\n",
       "      <td>The accuracy paradox is the paradoxical findin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Action model learning</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Action_model_lea...</td>\n",
       "      <td>Action model learning(sometimes abbreviated ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  \\\n",
       "0              Outline of computer vision   \n",
       "1  Outline of natural language processing   \n",
       "2                     Outline of robotics   \n",
       "3                        Accuracy paradox   \n",
       "4                   Action model learning   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://en.wikipedia.org/wiki/Outline_of_compu...   \n",
       "1  https://en.wikipedia.org/wiki/Outline_of_natur...   \n",
       "2  https://en.wikipedia.org/wiki/Outline_of_robotics   \n",
       "3     https://en.wikipedia.org/wiki/Accuracy_paradox   \n",
       "4  https://en.wikipedia.org/wiki/Action_model_lea...   \n",
       "\n",
       "                                    original_article  \n",
       "0  The following outline is provided as an overvi...  \n",
       "1  The following outline is provided as an overvi...  \n",
       "2  The following outline is provided as an overvi...  \n",
       "3  The accuracy paradox is the paradoxical findin...  \n",
       "4  Action model learning(sometimes abbreviated ac...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://en.wikipedia.org/wiki/Outline_of_compu...\n",
       "1    https://en.wikipedia.org/wiki/Outline_of_natur...\n",
       "2    https://en.wikipedia.org/wiki/Outline_of_robotics\n",
       "3       https://en.wikipedia.org/wiki/Accuracy_paradox\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pun_trans = str.maketrans(\" \", ' ',string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove punctuation from titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.str.translate(pun_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                outline of computer vision\n",
       "1    outline of natural language processing\n",
       "2                       outline of robotics\n",
       "3                          accuracy paradox\n",
       "4                     action model learning\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.apply(lambda x: [w for w in x if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [outline, computer, vision]\n",
       "1    [outline, natural, language, processing]\n",
       "2                         [outline, robotics]\n",
       "3                         [accuracy, paradox]\n",
       "4                   [action, model, learning]\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.apply(c.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common = c.most_common(100)\n",
    "#it's a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = [x[0] for x in most_common]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2idx = {key: value for (value, key) in enumerate(common_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['list', 'analysis', 'theory', 'model', 'data', 'learning', 'software', 'algorithm', 'system', 'language', 'programming', 'information', 'computer', 'intelligence', 'network', 'problem', 'theorem', 'artificial', 'machine', 'science', 'design', 'function', 'statistics', 'management', 'neural', 'comparison', 'search', 'processing', 'computational', 'optimization', 'computing', 'space', 'regression', 'distribution', 'control', 'method', 'mathematics', 'systems', 'matrix', 'linear', 'engineering', 'process', 'semantic', 'random', 'statistical', 'probability', 'social', 'product', 'markov', 'clustering', 'law', 'image', 'paradox', 'error', 'graph', 'modeling', 'mathematical', 'quantum', 'tree', 'kernel', 'detection', 'research', 'bayesian', 'stochastic', 'transform', 'technology', 'robot', 'genetic', 'estimation', 'digital', 'game', 'test', 'code', 'decision', 'logic', 'architecture', 'marketing', 'recognition', 'cognitive', 'coding', 'robotics', 'selection', 'evolution', 'web', 'mean', 'generalized', 'natural', 'automation', 'matching', 'equation', 'set', 'fuzzy', 'methods', 'video', 'structure', 'map', 'entropy', 'molecular', 'development', 'simulation'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2idx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2idx['natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for (k,v) in w2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'theory'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7316, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = df.original_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles = articles.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.str.translate(pun_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.apply(lambda x: [w for w in x if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [following, outline, provided, overview, topic...\n",
       "1    [following, outline, provided, overview, topic...\n",
       "2    [following, outline, provided, overview, topic...\n",
       "3    [accuracy, paradox, paradoxical, finding, accu...\n",
       "4    [action, model, learningsometimes, abbreviated...\n",
       "Name: original_article, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['articles'] = articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get document embeddings somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_length = articles.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7316.000000\n",
       "mean      1077.317660\n",
       "std       1207.922826\n",
       "min          2.000000\n",
       "25%        297.000000\n",
       "50%        663.500000\n",
       "75%       1382.000000\n",
       "max      10713.000000\n",
       "Name: original_article, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea - truncate documents to the first 500 words, make a matrix with embeddings per word in the input, run a cnn on it, and train the classifier to recognize topics from abstract titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    "MAX_TERMS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in df.articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(num_topics, current_corpus, current_dictionary):\n",
    "    lda_model = models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=current_dictionary)\n",
    "\n",
    "    lsi_model = models.LsiModel(corpus=corpus, num_topics=num_topics, id2word=current_dictionary)\n",
    "    \n",
    "    return lda_model, lsi_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, lsi_model = try_models(NUM_TOPICS, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_lists(model, num_topics, max_terms):\n",
    "    term_list = []\n",
    "    for idx in range(num_topics):\n",
    "        # Print the first 10 most representative topics\n",
    "        s = model.print_topic(idx, max_terms)\n",
    "        terms = s.split('\"')[1::2]\n",
    "        term_list.append(terms)\n",
    "        #print(\"Topic #%s:\" % idx, s.split('\"')[1::2])\n",
    "        #print(term_list[idx])\n",
    "    return term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list = get_term_lists(lda_model, NUM_TOPICS, MAX_TERMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_list = get_term_lists(lsi_model, 10,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I need to compare terms between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(lda_list[0]) & set(lsi_list[0])))/MAX_TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_terms_in_common(list1, list2,num_topics):\n",
    "    common = np.zeros(num_topics)\n",
    "    for idx in range(num_topics):\n",
    "        common[idx] = len(list(set(list1[idx]) & set(list2[idx])))\n",
    "        #print(\"proportion of topics in common: \",common[idx])\n",
    "    #print(\"mean: \", common.mean())\n",
    "    \n",
    "    return common.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_terms_in_common(lda_list, lsi_list,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now to pipeline this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, lsi_model = try_models(NUM_TOPICS, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.296"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_list = get_term_lists(lda_model, NUM_TOPICS, MAX_TERMS)\n",
    "lsi_list = get_term_lists(lsi_model, NUM_TOPICS,MAX_TERMS)\n",
    "mean_terms_in_common(lda_list, lsi_list,NUM_TOPICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going to try different numbers of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topic_list = [5,8,10,15,20]\n",
    "max_terms = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying 5 topics: \n",
      "there's a mean value of 38 terms in common between models\n",
      "trying 8 topics: \n",
      "there's a mean value of 33 terms in common between models\n",
      "trying 10 topics: \n",
      "there's a mean value of 32 terms in common between models\n",
      "trying 15 topics: \n",
      "there's a mean value of 30 terms in common between models\n",
      "trying 20 topics: \n",
      "there's a mean value of 27 terms in common between models\n"
     ]
    }
   ],
   "source": [
    "for n in num_topic_list:\n",
    "    lda_model, lsi_model = try_models(n, corpus, dictionary)\n",
    "    lda_list = get_term_lists(lda_model, n, max_terms)\n",
    "    lsi_list = get_term_lists(lsi_model, n,max_terms)\n",
    "    print(\"trying %d topics: \" % n)\n",
    "    print(\"there's a mean value of %d terms in common per topic between models\" % mean_terms_in_common(lda_list, lsi_list,n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
