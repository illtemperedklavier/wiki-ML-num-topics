{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\alecr\\Projects\\assignments\\Korbit_B\\wikipedia_machine_learning.csv\", sep='\\t')\n",
    "\n",
    "articles = data.apply(lambda x: x[2], axis=1)\n",
    "titles = data.apply(lambda x: x[0], axis=1)\n",
    "urls = data.apply(lambda x: x[1], axis=1)\n",
    "\n",
    "articles = data.apply(lambda x: x[2], axis=1)\n",
    "titles = data.apply(lambda x: x[0], axis=1)\n",
    "urls = data.apply(lambda x: x[1], axis=1)\n",
    "df = pd.concat([titles,urls,articles],axis=1)\n",
    "df.columns = ['title', 'url','original_article']\n",
    "df.dropna(inplace=True)\n",
    "pun_trans = str.maketrans(\" \", ' ',string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title']\n",
    "titles = titles.str.lower()\n",
    "titles = titles.str.translate(pun_trans)\n",
    "titles = titles.apply(word_tokenize)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "titles = titles.apply(lambda x: [w for w in x if w not in stop_words])\n",
    "titles.head()\n",
    "c = Counter()\n",
    "titles = titles.apply(c.update)\n",
    "most_common = c.most_common(100)\n",
    "#it's a list\n",
    "\n",
    "common_words = [x[0] for x in most_common]\n",
    "w2idx = {key: value for (value, key) in enumerate(common_words)}\n",
    "idx2word = {v:k for (k,v) in w2idx.items()}\n",
    "df['title'] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = df.original_article\n",
    "articles = articles.str.lower()\n",
    "articles = articles.str.translate(pun_trans)\n",
    "articles = articles.apply(word_tokenize) \n",
    "articles = articles.apply(lambda x: [w for w in x if w not in stop_words])\n",
    "df['articles'] = articles\n",
    "article_length = articles.apply(lambda x: len(x))\n",
    "#article_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained word vectors\n"
     ]
    }
   ],
   "source": [
    "vec_model = Word2Vec(df.articles, size=100, window=5, min_count=1, workers=4)\n",
    "print(\"trained word vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vec_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_words = vec_model.wv.word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corresponding_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = vec_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vec_model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(vec_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "for word in words:\n",
    "    vecs.append(vec_model.wv.__getitem__(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now to cluster the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10 #for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(vecs)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('logacec', 0.9920075535774231), ('eos', 0.9901856780052185), ('◌ᷣ', 0.9897794723510742), ('estacord', 0.9894852638244629), ('utoaztecan', 0.9892852902412415), ('⅚', 0.9891842603683472), ('ᵊ', 0.9889243245124817), ('и', 0.9889062643051147), ('qui', 0.9884096384048462), ('eines', 0.9883979558944702)] is a topic\n",
      "[('ignoring', 0.8320795297622681), ('secondly', 0.8274404406547546), ('accordingly', 0.8174997568130493), ('encounterson', 0.8086532354354858), ('unless', 0.8082488179206848), ('978047154397', 0.8056886196136475), ('therefore', 0.8044143319129944), ('ifij', 0.8034350872039795), ('ignore', 0.8030105829238892), ('consequently', 0.7990236282348633)] is a topic\n",
      "[('fibers', 0.892797589302063), ('emit', 0.8908559679985046), ('substrate', 0.8802881836891174), ('sediment', 0.8764002919197083), ('extracellular', 0.8736078143119812), ('gel', 0.8725701570510864), ('melanosomes', 0.870877206325531), ('skull', 0.8682500123977661), ('chemically', 0.8680864572525024), ('nuclei', 0.867196798324585)] is a topic\n",
      "[('jonathan', 0.9643033742904663), ('bruce', 0.9603285193443298), ('chris', 0.9584535360336304), ('warren', 0.958087146282196), ('tony', 0.9577470421791077), ('nelson', 0.9551973342895508), ('ian', 0.9543054699897766), ('arnold', 0.9540134072303772), ('davis', 0.9531351327896118), ('collins', 0.9526130557060242)] is a topic\n",
      "[('pension', 0.8877784609794617), ('encouraging', 0.8867931962013245), ('organisations', 0.8742960691452026), ('companys', 0.8732141256332397), ('contractors', 0.8690201044082642), ('partners', 0.8676463961601257), ('litigation', 0.8657183051109314), ('employee', 0.8632463812828064), ('oversight', 0.8587021827697754), ('managers', 0.857269823551178)] is a topic\n",
      "[('monotonic', 0.910953938961029), ('parametrization', 0.9057177305221558), ('dt', 0.8986859917640686), ('pointwise', 0.8982800841331482), ('varphi', 0.8933069109916687), ('equivalently', 0.8913511037826538), ('quotient', 0.8911837935447693), ('interpolant', 0.8896192908287048), ('gx', 0.873794436454773), ('mathbfa', 0.8734545707702637)] is a topic\n",
      "[('etl', 0.8681624531745911), ('spreadsheet', 0.8488755822181702), ('textbased', 0.8426733016967773), ('compiling', 0.8394765257835388), ('clientside', 0.8361492156982422), ('layout', 0.828349769115448), ('rolap', 0.8271738290786743), ('debugging', 0.8259176015853882), ('userfriendly', 0.8221311569213867), ('asynchronous', 0.821790337562561)] is a topic\n",
      "[('از', 0.987675130367279), ('и', 0.9871205687522888), ('logarithmen', 0.9865650534629822), ('ᵐ', 0.9862017631530762), ('―', 0.9861950874328613), ('kunaduletule', 0.9852550625801086), ('63323', 0.9852414131164551), ('79327', 0.9851359128952026), ('seriesfm', 0.9851311445236206), ('dezibel', 0.9850931167602539)] is a topic\n",
      "[('nonetheless', 0.8944681882858276), ('regards', 0.8719592094421387), ('conceptions', 0.8713374733924866), ('normative', 0.8525772094726562), ('implications', 0.8427447080612183), ('conceptualization', 0.8417689800262451), ('understandings', 0.8354446887969971), ('genuine', 0.8348366022109985), ('speculative', 0.8289284706115723), ('explaining', 0.8287298679351807)] is a topic\n",
      "[('sultan', 0.9596088528633118), ('sunday', 0.9545230269432068), ('funeral', 0.9511338472366333), ('nationalists', 0.9505665898323059), ('wrestling', 0.9485700130462646), ('celebration', 0.9470204710960388), ('legend', 0.9466912150382996), ('prayerthe', 0.9466645121574402), ('thailand', 0.9463708400726318), ('burial', 0.94590824842453)] is a topic\n"
     ]
    }
   ],
   "source": [
    "for center in kmeans.cluster_centers_:\n",
    "    topic = vec_model.wv.similar_by_vector(center)\n",
    "    print(\"%s is a topic\" % topic)\n",
    "    \"/n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logacec', 0.9920075535774231),\n",
       " ('eos', 0.9901856780052185),\n",
       " ('◌ᷣ', 0.9897794723510742),\n",
       " ('estacord', 0.9894852638244629),\n",
       " ('utoaztecan', 0.9892852902412415),\n",
       " ('⅚', 0.9891842603683472),\n",
       " ('ᵊ', 0.9889243245124817),\n",
       " ('и', 0.9889062643051147),\n",
       " ('qui', 0.9884096384048462),\n",
       " ('eines', 0.9883979558944702)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_model.wv.similar_by_vector(kmeans.cluster_centers_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_words():\n",
    "    terms = []\n",
    "    for center in kmeans.cluster_centers_:\n",
    "        topic = vec_model.wv.similar_by_vector(center)\n",
    "        topic = [t[0] for t in topic]\n",
    "        terms.append(topic)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = get_topic_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['logacec',\n",
       "  'eos',\n",
       "  '◌ᷣ',\n",
       "  'estacord',\n",
       "  'utoaztecan',\n",
       "  '⅚',\n",
       "  'ᵊ',\n",
       "  'и',\n",
       "  'qui',\n",
       "  'eines'],\n",
       " ['ignoring',\n",
       "  'secondly',\n",
       "  'accordingly',\n",
       "  'encounterson',\n",
       "  'unless',\n",
       "  '978047154397',\n",
       "  'therefore',\n",
       "  'ifij',\n",
       "  'ignore',\n",
       "  'consequently'],\n",
       " ['fibers',\n",
       "  'emit',\n",
       "  'substrate',\n",
       "  'sediment',\n",
       "  'extracellular',\n",
       "  'gel',\n",
       "  'melanosomes',\n",
       "  'skull',\n",
       "  'chemically',\n",
       "  'nuclei'],\n",
       " ['jonathan',\n",
       "  'bruce',\n",
       "  'chris',\n",
       "  'warren',\n",
       "  'tony',\n",
       "  'nelson',\n",
       "  'ian',\n",
       "  'arnold',\n",
       "  'davis',\n",
       "  'collins'],\n",
       " ['pension',\n",
       "  'encouraging',\n",
       "  'organisations',\n",
       "  'companys',\n",
       "  'contractors',\n",
       "  'partners',\n",
       "  'litigation',\n",
       "  'employee',\n",
       "  'oversight',\n",
       "  'managers'],\n",
       " ['monotonic',\n",
       "  'parametrization',\n",
       "  'dt',\n",
       "  'pointwise',\n",
       "  'varphi',\n",
       "  'equivalently',\n",
       "  'quotient',\n",
       "  'interpolant',\n",
       "  'gx',\n",
       "  'mathbfa'],\n",
       " ['etl',\n",
       "  'spreadsheet',\n",
       "  'textbased',\n",
       "  'compiling',\n",
       "  'clientside',\n",
       "  'layout',\n",
       "  'rolap',\n",
       "  'debugging',\n",
       "  'userfriendly',\n",
       "  'asynchronous'],\n",
       " ['از',\n",
       "  'и',\n",
       "  'logarithmen',\n",
       "  'ᵐ',\n",
       "  '―',\n",
       "  'kunaduletule',\n",
       "  '63323',\n",
       "  '79327',\n",
       "  'seriesfm',\n",
       "  'dezibel'],\n",
       " ['nonetheless',\n",
       "  'regards',\n",
       "  'conceptions',\n",
       "  'normative',\n",
       "  'implications',\n",
       "  'conceptualization',\n",
       "  'understandings',\n",
       "  'genuine',\n",
       "  'speculative',\n",
       "  'explaining'],\n",
       " ['sultan',\n",
       "  'sunday',\n",
       "  'funeral',\n",
       "  'nationalists',\n",
       "  'wrestling',\n",
       "  'celebration',\n",
       "  'legend',\n",
       "  'prayerthe',\n",
       "  'thailand',\n",
       "  'burial']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "having gotten a reasonable list of word groups - they do seem like words that appear near each other within clusters, the next task is to figure out a way to evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the topic categories are good, that should mean that the topics should be consistent across sentences taken from articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
