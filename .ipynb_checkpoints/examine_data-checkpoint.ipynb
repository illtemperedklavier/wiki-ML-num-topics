{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Data\\wikipedia-ml\\wikipedia_machine_learning.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the data is that each row is a series, and each series has 3 elements: 0:title, 1: url, 2: body text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outline of computer vision'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Outline_of_computer_vision'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following outline is provided as an overview of and topical guide to computer vision: Computer v'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0[2][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7318, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data.apply(lambda x: x[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data.apply(lambda x: x[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = data.apply(lambda x: x[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([titles,urls,articles],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['title', 'url','original_article']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next stage is to apply typical NLP preprocessing steps before looking at what words tend to be used often:\n",
    "- lowercase\n",
    "- remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[float, str]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([type(a) for a in df.article]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df[df['article'].apply(lambda x: isinstance(x, float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>Category:Robotics suites</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Category:Robotic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5449</td>\n",
       "      <td>Category:Search algorithms</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Category:Search_...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "100     Category:Robotics suites   \n",
       "5449  Category:Search algorithms   \n",
       "\n",
       "                                                    url article  \n",
       "100   https://en.wikipedia.org/wiki/Category:Robotic...     NaN  \n",
       "5449  https://en.wikipedia.org/wiki/Category:Search_...     NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's not many nulls, I'm just going to drop them, I'd check the proportion of nulls, but since the number of instances is in the thousands, and this is 2, I'm just going to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7316, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='any')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles = df['article'].apply(lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to create a dataframe with a column for each word, where the row is the count of that word in that article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    " from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles = articles.apply(lambda row: nltk.word_tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, following, outline, is, provided, as, an...\n",
       "1    [the, following, outline, is, provided, as, an...\n",
       "2    [the, following, outline, is, provided, as, an...\n",
       "3    [the, accuracy, paradox, is, the, paradoxical,...\n",
       "4    [action, model, learning, (, sometimes, abbrev...\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df['tokenized_sents'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was conservative with removing the punctuation, because some of it might be important, like ? especially, and =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = \"()'',.:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following',\n",
       " 'outline',\n",
       " 'provided',\n",
       " 'overview',\n",
       " 'topical',\n",
       " 'guide',\n",
       " 'computer',\n",
       " 'vision',\n",
       " ':',\n",
       " 'computer',\n",
       " 'vision',\n",
       " '–',\n",
       " 'interdisciplinary',\n",
       " 'field',\n",
       " 'deals',\n",
       " 'computers',\n",
       " 'made',\n",
       " 'gain',\n",
       " 'high-level',\n",
       " 'understanding',\n",
       " 'digital',\n",
       " 'images',\n",
       " 'videos',\n",
       " 'perspective',\n",
       " 'engineering',\n",
       " 'seeks',\n",
       " 'automate',\n",
       " 'tasks',\n",
       " 'human',\n",
       " 'visual',\n",
       " 'system',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'tasks',\n",
       " 'include',\n",
       " 'methods',\n",
       " 'acquiring',\n",
       " 'digital',\n",
       " 'images',\n",
       " 'image',\n",
       " 'sensors',\n",
       " 'image',\n",
       " 'processing',\n",
       " 'image',\n",
       " 'analysis',\n",
       " 'reach',\n",
       " 'understanding',\n",
       " 'digital',\n",
       " 'images',\n",
       " 'general',\n",
       " 'deals',\n",
       " 'extraction',\n",
       " 'high-dimensional',\n",
       " 'data',\n",
       " 'real',\n",
       " 'world',\n",
       " 'order',\n",
       " 'produce',\n",
       " 'numerical',\n",
       " 'symbolic',\n",
       " 'information',\n",
       " 'computer',\n",
       " 'interpret',\n",
       " 'image',\n",
       " 'data',\n",
       " 'take',\n",
       " 'many',\n",
       " 'forms',\n",
       " 'video',\n",
       " 'sequences',\n",
       " 'views',\n",
       " 'multiple',\n",
       " 'cameras',\n",
       " 'multi-dimensional',\n",
       " 'data',\n",
       " 'medical',\n",
       " 'scanner',\n",
       " 'technological',\n",
       " 'discipline',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'seeks',\n",
       " 'apply',\n",
       " 'theories',\n",
       " 'models',\n",
       " 'construction',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'systems',\n",
       " 'scientific',\n",
       " 'discipline',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'concerned',\n",
       " 'theory',\n",
       " 'behind',\n",
       " 'artificial',\n",
       " 'systems',\n",
       " 'extract',\n",
       " 'information',\n",
       " 'images',\n",
       " '==',\n",
       " 'branches',\n",
       " 'computer',\n",
       " 'vision==',\n",
       " 'computer',\n",
       " 'stereo',\n",
       " 'underwater',\n",
       " 'computer',\n",
       " '==',\n",
       " 'history',\n",
       " 'computer',\n",
       " 'vision==',\n",
       " 'history',\n",
       " 'computer',\n",
       " '==',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'subsystems==',\n",
       " '===',\n",
       " 'image',\n",
       " 'enhancement===',\n",
       " 'image',\n",
       " 'image',\n",
       " 'histogram',\n",
       " 'tone',\n",
       " 'gamma',\n",
       " 'anisotropic',\n",
       " 'diffusion',\n",
       " '===',\n",
       " 'transformations===',\n",
       " 'affine',\n",
       " 'homography',\n",
       " 'hough',\n",
       " 'radon',\n",
       " 'walsh–hadamard',\n",
       " '===',\n",
       " 'filtering',\n",
       " 'fourier',\n",
       " 'wavelet',\n",
       " 'transforms',\n",
       " 'image',\n",
       " 'compression===',\n",
       " 'image',\n",
       " 'filter',\n",
       " 'gabor',\n",
       " 'jpeg',\n",
       " 'adaptive',\n",
       " '===',\n",
       " 'color',\n",
       " 'vision===',\n",
       " 'visual',\n",
       " 'human',\n",
       " 'visual',\n",
       " 'system',\n",
       " 'color',\n",
       " 'matching',\n",
       " 'color',\n",
       " 'color',\n",
       " 'appearance',\n",
       " 'color',\n",
       " 'management',\n",
       " 'color',\n",
       " 'color',\n",
       " 'color',\n",
       " '===',\n",
       " 'feature',\n",
       " 'extraction===',\n",
       " 'active',\n",
       " 'blob',\n",
       " 'canny',\n",
       " 'edge',\n",
       " 'contour',\n",
       " 'edge',\n",
       " 'edge',\n",
       " 'harris',\n",
       " 'corner',\n",
       " 'random',\n",
       " 'sample',\n",
       " 'consensus',\n",
       " 'scale-invariant',\n",
       " 'feature',\n",
       " 'transform',\n",
       " '===',\n",
       " 'pose',\n",
       " 'estimation===',\n",
       " 'bundle',\n",
       " 'articulated',\n",
       " 'body',\n",
       " 'pose',\n",
       " 'estimation',\n",
       " 'direct',\n",
       " 'linear',\n",
       " 'transformation',\n",
       " 'epipolar',\n",
       " 'fundamental',\n",
       " 'pinhole',\n",
       " 'camera',\n",
       " 'projective',\n",
       " 'trifocal',\n",
       " '===',\n",
       " 'registration===',\n",
       " 'active',\n",
       " 'appearance',\n",
       " 'model',\n",
       " 'cross-',\n",
       " 'geometric',\n",
       " 'graph',\n",
       " 'cut',\n",
       " 'least',\n",
       " 'squares',\n",
       " 'image',\n",
       " 'image',\n",
       " 'level-set',\n",
       " 'markov',\n",
       " 'random',\n",
       " 'medial',\n",
       " 'motion',\n",
       " 'motion',\n",
       " 'multispectral',\n",
       " 'normalized',\n",
       " 'cut',\n",
       " 'optical',\n",
       " 'particle',\n",
       " 'scale',\n",
       " '===',\n",
       " 'visual',\n",
       " 'recognition===',\n",
       " 'object',\n",
       " 'scale-invariant',\n",
       " 'feature',\n",
       " 'transform',\n",
       " 'gesture',\n",
       " 'bag-of-words',\n",
       " 'model',\n",
       " 'computer',\n",
       " 'kadir–brady',\n",
       " 'saliency',\n",
       " '==',\n",
       " 'commercial',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'systems==',\n",
       " 'aphelion',\n",
       " 'microsoft',\n",
       " 'poseidon',\n",
       " 'drowning',\n",
       " 'detection',\n",
       " 'visage',\n",
       " '==',\n",
       " 'applications==',\n",
       " '3d',\n",
       " 'reconstruction',\n",
       " 'multiple',\n",
       " 'audio-visual',\n",
       " 'speech',\n",
       " 'augmented',\n",
       " 'augmented',\n",
       " 'reality-assisted',\n",
       " 'automated',\n",
       " 'optical',\n",
       " 'automatic',\n",
       " 'image',\n",
       " 'automatic',\n",
       " 'number',\n",
       " 'plate',\n",
       " 'automatic',\n",
       " 'target',\n",
       " 'check',\n",
       " 'closed-circuit',\n",
       " 'computer',\n",
       " 'stereo',\n",
       " 'contextual',\n",
       " 'image',\n",
       " 'darpa',\n",
       " 'lagr',\n",
       " 'digital',\n",
       " 'video',\n",
       " 'document',\n",
       " 'facial',\n",
       " 'recognition',\n",
       " 'geometric',\n",
       " 'feature',\n",
       " 'gesture',\n",
       " 'image',\n",
       " 'collection',\n",
       " 'image',\n",
       " 'content-based',\n",
       " 'image',\n",
       " 'reverse',\n",
       " 'image',\n",
       " 'image-based',\n",
       " 'modeling',\n",
       " 'integrated',\n",
       " 'mail',\n",
       " 'iris',\n",
       " 'machine',\n",
       " 'mobile',\n",
       " 'navigation',\n",
       " 'system',\n",
       " 'components',\n",
       " ':',\n",
       " 'autonomous',\n",
       " 'mobile',\n",
       " 'object',\n",
       " 'optical',\n",
       " 'braille',\n",
       " 'optical',\n",
       " 'character',\n",
       " 'intelligent',\n",
       " 'character',\n",
       " 'pedestrian',\n",
       " 'people',\n",
       " 'physical',\n",
       " 'red',\n",
       " 'light',\n",
       " 'remote',\n",
       " 'smart',\n",
       " 'traffic',\n",
       " 'enforcement',\n",
       " 'traffic',\n",
       " 'sign',\n",
       " 'vehicle',\n",
       " 'infrastructure',\n",
       " 'velocity',\n",
       " 'video',\n",
       " 'content',\n",
       " 'view',\n",
       " 'visual',\n",
       " 'sensor',\n",
       " 'visual',\n",
       " 'water',\n",
       " 'remote',\n",
       " '==',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'companies==',\n",
       " 'cognex',\n",
       " 'isra',\n",
       " 'omek',\n",
       " 'scantron',\n",
       " 'view',\n",
       " '==',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'publications==',\n",
       " 'electronic',\n",
       " 'letters',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'image',\n",
       " 'international',\n",
       " 'journal',\n",
       " 'computer',\n",
       " '==',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'organizations==',\n",
       " 'conference',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'pattern',\n",
       " 'european',\n",
       " 'conference',\n",
       " 'computer',\n",
       " 'international',\n",
       " 'conference',\n",
       " 'computer',\n",
       " 'international',\n",
       " 'conferences',\n",
       " 'central',\n",
       " 'europe',\n",
       " 'computer',\n",
       " 'graphics',\n",
       " 'visualization',\n",
       " 'computer',\n",
       " '==',\n",
       " 'persons',\n",
       " 'influential',\n",
       " 'computer',\n",
       " 'vision==',\n",
       " '==',\n",
       " 'see',\n",
       " 'also==',\n",
       " 'outline',\n",
       " 'artificial',\n",
       " 'outline',\n",
       " 'list',\n",
       " 'computer',\n",
       " 'graphics',\n",
       " 'descriptive',\n",
       " 'geometry',\n",
       " 'virtual',\n",
       " 'design',\n",
       " '==',\n",
       " 'references==',\n",
       " '==',\n",
       " 'external',\n",
       " 'links==',\n",
       " 'usc',\n",
       " 'iris',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'conference',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'papers',\n",
       " 'web',\n",
       " 'complete',\n",
       " 'list',\n",
       " 'papers',\n",
       " 'relevant',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'conferences',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'online',\n",
       " 'news',\n",
       " 'source',\n",
       " 'code',\n",
       " 'datasets',\n",
       " 'job',\n",
       " 'offers',\n",
       " 'related',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'keith',\n",
       " 'price',\n",
       " \"'s\",\n",
       " 'annotated',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'cvonline',\n",
       " 'bob',\n",
       " 'fisher',\n",
       " \"'s\",\n",
       " 'compendium',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'british',\n",
       " 'machine',\n",
       " 'vision',\n",
       " 'association',\n",
       " 'supporting',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'research',\n",
       " 'within',\n",
       " 'uk',\n",
       " 'via',\n",
       " 'bmvc',\n",
       " 'miua',\n",
       " 'conferences',\n",
       " 'annals',\n",
       " 'bmva',\n",
       " 'open-source',\n",
       " 'journal',\n",
       " 'bmva',\n",
       " 'summer',\n",
       " 'school',\n",
       " 'one-day',\n",
       " 'meetings']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in t if w not in stop_words and w not in punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to remove punctuation as well as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted(tokens):\n",
    "    tokens = [w for w in t if w not in stop_words and w not in punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"()'',.\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = articles.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.apply(lambda x: [w for w in x if w not in stop_words and w not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7316,)\n",
      "(7316, 3)\n"
     ]
    }
   ],
   "source": [
    "print(articles.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('article',axis=1)\n",
    "df['article']=articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next: sort columns by count frequency\n",
    "\n",
    "next make a dataframe with the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Something like this https://www.aclweb.org/anthology/W15-1526.pdf would be good to try - supposedly outperforms LDA, but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = articles.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7316.000000\n",
       "mean      1324.216785\n",
       "std       1505.295536\n",
       "min          4.000000\n",
       "25%        346.000000\n",
       "50%        808.000000\n",
       "75%       1711.000000\n",
       "max      17054.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, discarding articles with less than a threshold of non-stopwords will help train an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
